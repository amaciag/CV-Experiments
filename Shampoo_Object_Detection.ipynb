{"nbformat":4,"nbformat_minor":2,"metadata":{"colab":{"name":"Untitled0.ipynb","provenance":[],"authorship_tag":"ABX9TyMwQWucI98sbK8CdmEbQWC8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# **Object Detection**"],"metadata":{}},{"cell_type":"markdown","source":["<a target=\"_blank\" href=\"https://github.com/amaciag/CV-Experiments/blob/main/Shampoo_Object_Detection.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\"/>View source on GitHub</a>"],"metadata":{}},{"cell_type":"markdown","source":["Object Detection is the supervised learning process of locating and identifying objects in an image or video. This tutorial shows how to use some Google tensorflow pretrained model to train on a shampoo image dataset. Transfer learning and data augmentation techniques are incorporated."],"metadata":{}},{"cell_type":"markdown","source":["## **Install and import appropriate modules and their dependencies**"],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["from __future__ import absolute_import, division, print_function, unicode_literals\n","\n","import io\n","import json\n","import os\n","import pandas as pd\n","import requests\n","import tensorflow as tf\n","\n","from google.colab import drive\n","from IPython.display import Javascript\n","from PIL import Image\n","\n","def resize_output_cell():\n","  display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 300})'''))\n","\n","get_ipython().events.register('pre_run_cell', resize_output_cell)\n","drive.mount('/content/drive')"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ks2qm8O3Enj2","executionInfo":{"status":"ok","timestamp":1643296840270,"user_tz":-60,"elapsed":314,"user":{"displayName":"Anh Maciag","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjur-jNtzXZt6W_z-Jr2vWN1IkrFdQjwISgJ4pqbg=s64","userId":"01164446871095954383"}},"outputId":"8a50082f-f8a6-47d0-f5f8-221c18cdf06e"}},{"cell_type":"code","execution_count":null,"source":["!git clone https://github.com/tensorflow/models"],"outputs":[],"metadata":{"id":"N89qp8TWJsdR"}},{"cell_type":"code","execution_count":null,"source":["# Replace setup.py in models repo with the following code\n","\n","%%writefile models/research/object_detection/packages/tf2/setup.py\n","\"\"\"Setup script for object_detection with TF2.0.\"\"\"\n","import os\n","from setuptools import find_packages\n","from setuptools import setup\n","\n","REQUIRED_PACKAGES = [\n","    # Required for apache-beam with PY3\n","    'avro-python3',\n","    'apache-beam',\n","    'pillow',\n","    'lxml',\n","    'matplotlib',\n","    'Cython',\n","    'contextlib2',\n","    'tf-slim',\n","    'six',\n","    'pycocotools',\n","    'lvis',\n","    'scipy',\n","    'pandas',\n","    'tf-models-official==2.7.0',\n","    'tensorflow_io',\n","    'keras'\n","]\n","\n","setup(\n","    name='object_detection',\n","    version='0.1',\n","    install_requires=REQUIRED_PACKAGES,\n","    include_package_data=True,\n","    packages=(\n","        [p for p in find_packages() if p.startswith('object_detection')] +\n","        find_packages(where=os.path.join('.', 'slim'))),\n","    package_dir={\n","        'datasets': os.path.join('slim', 'datasets'),\n","        'nets': os.path.join('slim', 'nets'),\n","        'preprocessing': os.path.join('slim', 'preprocessing'),\n","        'deployment': os.path.join('slim', 'deployment'),\n","        'scripts': os.path.join('slim', 'scripts'),\n","    },\n","    description='Tensorflow Object Detection Library',\n","    python_requires='>3.6',\n",")\n","\n"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["# Install object_detection package and its dependecies\n","\n","%%bash\n","\n","sudo apt install -y protobuf-compiler\n","cd models/research/\n","protoc object_detection/protos/*.proto --python_out=.\n","cp object_detection/packages/tf2/setup.py .\n","python -m pip install .\n","pip install opencv-python-headless==4.1.2.30"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SPg1ILoWE63M","executionInfo":{"status":"ok","timestamp":1643296852510,"user_tz":-60,"elapsed":10920,"user":{"displayName":"Anh Maciag","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjur-jNtzXZt6W_z-Jr2vWN1IkrFdQjwISgJ4pqbg=s64","userId":"01164446871095954383"}},"outputId":"bf0a24c2-7683-4b98-89d2-752175bb5162"}},{"cell_type":"markdown","source":["## **Create reuseable functions**"],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["from object_detection.utils import dataset_util, label_map_util\n","\n","def create_tf_example(data):\n","    \n","    # print(data['Labeled Data'])\n","    response = requests.get(data['Labeled Data'])\n","    encoded_jpg = response.content\n","    encoded_jpg_io = io.BytesIO(encoded_jpg)\n","    image = Image.open(encoded_jpg_io)\n","    width, height = image.size\n","\n","    xmins = []\n","    xmaxs = []\n","    ymins = []\n","    ymaxs = []\n","    classes_text = []\n","    classes = []\n","\n","    for obj in data['Label']['objects']:\n","        bbox = obj['bbox']\n","        xmin = bbox['left']\n","        ymin = bbox['top']\n","        xmax = xmin + bbox['width']\n","        ymax = ymin + bbox['height']\n","        xmins.append(xmin / width)\n","        xmaxs.append(xmax / width)\n","        ymins.append(ymin / height)\n","        ymaxs.append(ymax / height)\n","        classes_text.append(obj['title'].encode('utf8')) \n","        classes.append(label_map_dict[obj['title']])\n","    \n","    filename = data['External ID'].encode('utf8')\n","    image_format = b'jpg'\n","    tf_example = tf.train.Example(features=tf.train.Features(feature={\n","            'image/height': dataset_util.int64_feature(height),\n","            'image/width': dataset_util.int64_feature(width),\n","            'image/filename': dataset_util.bytes_feature(filename),\n","            'image/source_id': dataset_util.bytes_feature(filename),\n","            'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n","            'image/format': dataset_util.bytes_feature(image_format),\n","            'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n","            'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n","            'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n","            'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n","            'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n","            'image/object/class/label': dataset_util.int64_list_feature(classes),\n","        }))\n","    return tf_example\n","\n","def generate_tf_record(json_input, output_path, label_map):\n","\n","    global label_map_dict\n","    label_map_dict = label_map_util.get_label_map_dict(label_map)\n","    \n","    with tf.io.gfile.GFile(json_input, 'r') as file:\n","        dataset = json.load(file)\n","    \n","    writer = tf.io.TFRecordWriter(output_path)\n","    for data in dataset:\n","        tf_example = create_tf_example(data)\n","        writer.write(tf_example.SerializeToString())\n","    writer.close()\n","    print(f'Successfully created TF-records {output_path}')\n","\n","def update_pipeline_config(pipeline_config, args):\n","  \n","  pipeline_config['model'].ssd.num_classes=args['num_classes']\n","  pipeline_config['train_config'].batch_size=args['batch_size']\n","  pipeline_config['train_config'].fine_tune_checkpoint_type=args['fine_tune_checkpoint_type']\n","  pipeline_config['train_config'].fine_tune_checkpoint=args['fine_tune_checkpoint_path']\n","  pipeline_config['eval_input_config'].label_map_path=args['label_map_path']\n","  pipeline_config['eval_input_config'].tf_record_input_reader.input_path[0]=args['eval_input_path']\n","  pipeline_config['train_input_config'].label_map_path=args['label_map_path']\n","  pipeline_config['train_input_config'].tf_record_input_reader.input_path[0]=args['train_input_path']\n","  \n","  return pipeline_config\n","\n","def load_image_into_numpy_array(path):\n","    return np.array(Image.open(path))\n","\n","def get_prediction(image_url):\n","\n","  response = requests.get(image_url)\n","  encoded_jpg = response.content\n","  encoded = io.BytesIO(encoded_jpg)\n","  image_np = load_image_into_numpy_array(encoded)\n","  input_tensor = tf.convert_to_tensor(image_np)\n","  input_tensor = input_tensor[tf.newaxis, ...]\n","  detections = detect_fn(input_tensor)\n","\n","  # All outputs are batches tensors.\n","  # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n","  # We're only interested in the first num_detections.  \n","  num_detections = int(detections.pop('num_detections'))\n","  detections = {\n","      key: value[0, :num_detections].numpy()\n","      for key, value in detections.items()\n","  }\n","  detections['num_detections'] = num_detections\n","  detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n","\n","  return image_np, detections\n"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["## **Create directories and download shampoo image data**"],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["%%bash\n","\n","if [ ! -d workspace ]; then\n","  mkdir -p workspace/{pretrained_models,trained_models,data}\n","fi\n","\n","wget -O workspace/data/eval.json https://raw.githubusercontent.com/amaciag/CV-Experiments/main/data/eval.json\n","wget -O workspace/data/train.json https://raw.githubusercontent.com/amaciag/CV-Experiments/main/data/train.json"],"outputs":[],"metadata":{"id":"w-QHrCGdCygK"}},{"cell_type":"code","execution_count":null,"source":["items = [{\n","  'id': '1',\n","  'name': '\"Loreal\"'\n","},\n","{\n","  'id': '2',\n","  'name': '\"Pantene\"'\n","},\n","{\n","  'id': '3',\n","  'name': '\"Head_&_Shoulders\"'\n","}]\n","\n","expression = ''\n","for item in items:\n","  expression += 'item {\\n'\n","  for key,value in item.items():\n","    expression += 2*' ' + key + ': ' + value + '\\n'\n","  expression += '}\\n'\n","\n","with open('workspace/data/shampoo_label_map.pbtxt', 'w') as f:\n","  f.write(expression)\n","print(expression)"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["## **Save image data as tf records**"],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["generate_tf_record('workspace/data/train.json', 'workspace/data/train.record', 'workspace/data/shampoo_label_map.pbtxt')\n","generate_tf_record('workspace/data/eval.json', 'workspace/data/eval.record', 'workspace/data/shampoo_label_map.pbtxt')\n","\n","# !python generate_tf_record.py --json-input workspace/data/train.json --output-path workspace/data/train.record --label-map workspace/data/shampoo_label_map.pbtxt\n","# !python generate_tf_record.py --json-input workspace/data/eval.json --output-path workspace/data/eval.record --label-map workspace/data/shampoo_label_map.pbtxt"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["MODELS = {\n","    \"SSD MobileNet v2 320x320\":\"http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_320x320_coco17_tpu-8.tar.gz\",\n","    \"EfficientDet D0 512x512\": \"http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d0_coco17_tpu-32.tar.gz\",\n","    \"EfficientDet D2 768x768\": \"http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d2_coco17_tpu-32.tar.gz\"\n","}\n","\n","selected_model = \"SSD MobileNet v2 320x320\"\n","file = MODELS[selected_model].split('/')[-1]"],"outputs":[],"metadata":{"id":"akC8WVu5-1dC"}},{"cell_type":"code","execution_count":null,"source":["!wget {MODELS[selected_model]} --directory-prefix workspace/pretrained_models\n","!tar -xf workspace/pretrained_models/{file} -C workspace/pretrained_models"],"outputs":[],"metadata":{"id":"QO7ZJvGFFnfg","executionInfo":{"status":"ok","timestamp":1643296853425,"user_tz":-60,"elapsed":927,"user":{"displayName":"Anh Maciag","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjur-jNtzXZt6W_z-Jr2vWN1IkrFdQjwISgJ4pqbg=s64","userId":"01164446871095954383"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"272061df-c98f-4fed-bfe0-9ab0a5e30b5a"}},{"cell_type":"code","execution_count":null,"source":["from object_detection.utils import config_util\n","\n","model_dir = file.replace('.tar.gz', '')\n","pipeline_config_path = f'workspace/pretrained_models/{model_dir}/pipeline.config'\n","pipeline_config = config_util.get_configs_from_pipeline_file(pipeline_config_path)\n","\n","args = {'num_classes': 3, \n","        'batch_size': 4, \n","        'fine_tune_checkpoint_type': 'detection',\n","        'fine_tune_checkpoint_path': f'workspace/pretrained_models/{model_dir}/checkpoint/ckpt-0',\n","        'label_map_path': 'workspace/data/shampoo_label_map.pbtxt',\n","        'eval_input_path': 'workspace/data/eval.record',\n","        'train_input_path': 'workspace/data/train.record'}\n","\n","pipeline_config = update_pipeline_config(pipeline_config, args)        \n","pipeline_config = config_util.create_pipeline_proto_from_configs(pipeline_config)\n","config_util.save_pipeline_config(pipeline_config, 'workspace/trained_models')"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gTAnTu4sGqSy","executionInfo":{"status":"ok","timestamp":1643300171081,"user_tz":-60,"elapsed":4,"user":{"displayName":"Anh Maciag","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjur-jNtzXZt6W_z-Jr2vWN1IkrFdQjwISgJ4pqbg=s64","userId":"01164446871095954383"}},"outputId":"eeecad31-506e-41f2-834c-1db2941c678d"}},{"cell_type":"markdown","source":["## **Train a pretrained model**"],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["%reload_ext tensorboard\n","%tensorboard --logdir=drive/MyDrive/CV-Experiments-main/ssd_mobilenet/v1"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["!python models/research/object_detection/model_main_tf2.py --pipeline_config_path=workspace/trained_models/pipeline.config \\\n","  --model_dir=drive/MyDrive/CV-Experiments-main/ssd_mobilenet/v1 --checkpoint_every_n=100 --num_train_steps=1000 --alsologtostderr"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JvjGQgZKDaC5","executionInfo":{"status":"ok","timestamp":1643303708162,"user_tz":-60,"elapsed":731010,"user":{"displayName":"Anh Maciag","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjur-jNtzXZt6W_z-Jr2vWN1IkrFdQjwISgJ4pqbg=s64","userId":"01164446871095954383"}},"outputId":"2cc16b98-89e4-4d43-8345-f7275f66b935"}},{"cell_type":"code","execution_count":null,"source":["# LOG_DIR = 'workspace/efficientdet_d0/v1'\n","# get_ipython().system_raw(\n","#     'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n","#     .format(LOG_DIR)\n","# )"],"outputs":[],"metadata":{"id":"NO051KtxWEvo"}},{"cell_type":"code","execution_count":null,"source":["# get_ipython().system_raw('./ngrok http 6006 &')"],"outputs":[],"metadata":{"id":"-Zsd9Z9YdFwR"}},{"cell_type":"code","execution_count":null,"source":["# !curl -s http://localhost:4040/api/tunnels | python -c \\\n","#   \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vBgIIXRGWNRd","executionInfo":{"status":"ok","timestamp":1643302520114,"user_tz":-60,"elapsed":455,"user":{"displayName":"Anh Maciag","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjur-jNtzXZt6W_z-Jr2vWN1IkrFdQjwISgJ4pqbg=s64","userId":"01164446871095954383"}},"outputId":"fdb2d25b-2ff0-4a03-de3a-1cfed84d4ad2"}},{"cell_type":"markdown","source":["## **Get and visualize predictions**"],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["# %%bash\n","!cp models/research/object_detection/exporter_main_v2.py .\n","!python exporter_main_v2.py --input_type image_tensor \\\n","  --pipeline_config_path workspace/trained_models/pipeline.config  \\\n","  --trained_checkpoint_dir drive/MyDrive/CV-Experiments-main/ssd_mobilenet/v1 \\\n","  --output_directory sample_model"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["import time\n","import tensorflow as tf\n","from object_detection.utils import label_map_util\n","from object_detection.utils import visualization_utils as viz_utils\n","\n","PATH_TO_SAVED_MODEL = './sample_model/saved_model'\n","\n","detect_fn = tf.saved_model.load(PATH_TO_SAVED_MODEL)"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["import json\n","import requests\n","import io\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","%matplotlib inline\n","\n","with tf.io.gfile.GFile('workspace/data/eval.json', 'r') as file:\n","  eval_data = json.load(file)\n","\n","category_index = label_map_util.create_category_index_from_labelmap('./workspace/data/shampoo_label_map.pbtxt', use_display_name=True)\n","\n","for data in eval_data:\n","    \n","    url = data['Labeled Data']\n","    image_np, detections = get_prediction(url)\n","    viz_utils.visualize_boxes_and_labels_on_image_array(\n","          image_np,\n","          detections['detection_boxes'],\n","          detections['detection_classes'],\n","          detections['detection_scores'],\n","          category_index,\n","          use_normalized_coordinates=True,\n","          max_boxes_to_draw=200,\n","          min_score_thresh=.30,\n","          agnostic_mode=False)\n","    \n","    shampoo = category_index[detections['detection_classes'][np.argmax(np.max(detections['detection_multiclass_scores'], axis=1))]]['name']\n","    plt.figure(figsize=(20,20))\n","    plt.title(shampoo)\n","    plt.imshow(image_np)\n","    # plt.cla()\n","    # print('Done')\n","plt.show()"],"outputs":[],"metadata":{}}]}
{"cells":[{"cell_type":"markdown","metadata":{},"source":["# **Object Detection**"]},{"cell_type":"markdown","metadata":{},"source":["<a target=\"_blank\" href=\"https://github.com/amaciag/CV-Experiments/blob/main/Shampoo_Object_Detection.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\"/>View source on GitHub</a>"]},{"cell_type":"markdown","metadata":{},"source":["Object Detection is the supervised learning process of locating and identifying objects in an image or video. This tutorial shows how to use some Google tensorflow pretrained model to train on a shampoo image dataset. Transfer learning and data augmentation techniques are incorporated."]},{"cell_type":"markdown","metadata":{},"source":["## **Resize output cell size**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Set the default max height=300 for output cells\n","\n","from google.colab import drive\n","from IPython.display import Javascript\n","\n","def resize_output_cell(height=300):\n","  display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: %i})''' %height))\n","\n","get_ipython().events.register('pre_run_cell', resize_output_cell)"]},{"cell_type":"markdown","metadata":{},"source":["## **Install and import appropriate modules and their dependencies**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N89qp8TWJsdR"},"outputs":[],"source":["# Clone tensorflow/models repo\n","\n","!git clone https://github.com/tensorflow/models"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10920,"status":"ok","timestamp":1643296852510,"user":{"displayName":"Anh Maciag","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjur-jNtzXZt6W_z-Jr2vWN1IkrFdQjwISgJ4pqbg=s64","userId":"01164446871095954383"},"user_tz":-60},"id":"SPg1ILoWE63M","outputId":"bf0a24c2-7683-4b98-89d2-752175bb5162"},"outputs":[],"source":["# Install object_detection package and its dependecies\n","\n","%%bash\n","\n","sudo apt install -y protobuf-compiler\n","cd models/research/\n","protoc object_detection/protos/*.proto --python_out=.\n","cp object_detection/packages/tf2/setup.py .\n","python -m pip install .\n","pip install opencv-python-headless==4.1.2.30"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":314,"status":"ok","timestamp":1643296840270,"user":{"displayName":"Anh Maciag","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjur-jNtzXZt6W_z-Jr2vWN1IkrFdQjwISgJ4pqbg=s64","userId":"01164446871095954383"},"user_tz":-60},"id":"ks2qm8O3Enj2","outputId":"8a50082f-f8a6-47d0-f5f8-221c18cdf06e"},"outputs":[],"source":["# Import object_detection module and other Python libraries\n","\n","from __future__ import absolute_import, division, print_function, unicode_literals\n","\n","import io\n","import json\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import os\n","import pandas as pd\n","import requests\n","import tensorflow as tf\n","\n","from google.colab import drive\n","from IPython.display import Javascript\n","from object_detection.utils import config_util, dataset_util, label_map_util\n","from object_detection.utils import visualization_utils as viz_utils\n","from PIL import Image\n","\n","%matplotlib inline"]},{"cell_type":"markdown","metadata":{},"source":["## **Create reusable functions**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Create a tf example to store image features\n","# TF example is used to structure a TF Record\n","def create_tf_example(data):\n","    \n","    response = requests.get(data['Labeled Data'])\n","    encoded_jpg = response.content\n","    encoded_jpg_io = io.BytesIO(encoded_jpg)\n","    image = Image.open(encoded_jpg_io)\n","    width, height = image.size\n","\n","    xmins = []\n","    xmaxs = []\n","    ymins = []\n","    ymaxs = []\n","    classes_text = []\n","    classes = []\n","\n","    for obj in data['Label']['objects']:\n","        bbox = obj['bbox']\n","        xmin = bbox['left']\n","        ymin = bbox['top']\n","        xmax = xmin + bbox['width']\n","        ymax = ymin + bbox['height']\n","        xmins.append(xmin / width)\n","        xmaxs.append(xmax / width)\n","        ymins.append(ymin / height)\n","        ymaxs.append(ymax / height)\n","        classes_text.append(obj['title'].encode('utf8')) \n","        classes.append(label_map_dict[obj['title']])\n","    \n","    filename = data['External ID'].encode('utf8')\n","    image_format = b'jpg'\n","    tf_example = tf.train.Example(features=tf.train.Features(feature={\n","            'image/height': dataset_util.int64_feature(height),\n","            'image/width': dataset_util.int64_feature(width),\n","            'image/filename': dataset_util.bytes_feature(filename),\n","            'image/source_id': dataset_util.bytes_feature(filename),\n","            'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n","            'image/format': dataset_util.bytes_feature(image_format),\n","            'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n","            'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n","            'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n","            'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n","            'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n","            'image/object/class/label': dataset_util.int64_list_feature(classes),\n","        }))\n","    return tf_example\n","\n","# Generate a tf record by serializing a tf example into a binary format\n","# Binary data can be read more efficiently\n","def generate_tf_record(json_input, output_path, label_map):\n","\n","    global label_map_dict\n","    label_map_dict = label_map_util.get_label_map_dict(label_map)\n","    \n","    with tf.io.gfile.GFile(json_input, 'r') as file:\n","        dataset = json.load(file)\n","    \n","    writer = tf.io.TFRecordWriter(output_path)\n","    for data in dataset:\n","        tf_example = create_tf_example(data)\n","        writer.write(tf_example.SerializeToString())\n","    writer.close()\n","    print(f'Successfully created TF-records {output_path}')\n","\n","# Update a model's training configuration\n","def update_pipeline_config(pipeline_config, args):\n","  \n","  pipeline_config['model'].ssd.num_classes=args['num_classes']\n","  pipeline_config['train_config'].batch_size=args['batch_size']\n","  pipeline_config['train_config'].fine_tune_checkpoint_type=args['fine_tune_checkpoint_type']\n","  pipeline_config['train_config'].fine_tune_checkpoint=args['fine_tune_checkpoint_path']\n","  pipeline_config['eval_input_config'].label_map_path=args['label_map_path']\n","  pipeline_config['eval_input_config'].tf_record_input_reader.input_path[0]=args['eval_input_path']\n","  pipeline_config['train_input_config'].label_map_path=args['label_map_path']\n","  pipeline_config['train_input_config'].tf_record_input_reader.input_path[0]=args['train_input_path']\n","  \n","  return pipeline_config\n","\n","# Get an image numpy array\n","def load_image_into_numpy_array(path):\n","    return np.array(Image.open(path))\n","\n","# Get a single prediction\n","def get_prediction(image_url):\n","\n","  response = requests.get(image_url)\n","  encoded_jpg = response.content\n","  encoded = io.BytesIO(encoded_jpg)\n","  image_np = load_image_into_numpy_array(encoded)\n","  input_tensor = tf.convert_to_tensor(image_np)\n","  input_tensor = input_tensor[tf.newaxis, ...]\n","  detections = detect_fn(input_tensor)\n","\n","  # All outputs are batches tensors.\n","  # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n","  # We're only interested in the first num_detections.  \n","  num_detections = int(detections.pop('num_detections'))\n","  detections = {\n","      key: value[0, :num_detections].numpy()\n","      for key, value in detections.items()\n","  }\n","  detections['num_detections'] = num_detections\n","  detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n","\n","  return image_np, detections\n"]},{"cell_type":"markdown","metadata":{},"source":["## **Create directories and download shampoo image data**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w-QHrCGdCygK"},"outputs":[],"source":["%%bash\n","\n","if [ ! -d workspace ]; then\n","  mkdir -p workspace/{pretrained_models,trained_models,data}\n","fi\n","\n","wget -O workspace/data/eval.json https://raw.githubusercontent.com/amaciag/CV-Experiments/main/data/eval.json\n","wget -O workspace/data/train.json https://raw.githubusercontent.com/amaciag/CV-Experiments/main/data/train.json"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Encode labels through mapping\n","# Image background is represented as 0\n","\n","items = [{\n","  'id': '1',\n","  'name': '\"Loreal\"'\n","},\n","{\n","  'id': '2',\n","  'name': '\"Pantene\"'\n","},\n","{\n","  'id': '3',\n","  'name': '\"Head_&_Shoulders\"'\n","}]\n","\n","expression = ''\n","for item in items:\n","  expression += 'item {\\n'\n","  for key,value in item.items():\n","    expression += 2*' ' + key + ': ' + value + '\\n'\n","  expression += '}\\n'\n","\n","with open('workspace/data/shampoo_label_map.pbtxt', 'w') as f:\n","  f.write(expression)\n","print(expression)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Convert images into binary data\n","\n","generate_tf_record('workspace/data/train.json', 'workspace/data/train.record', 'workspace/data/shampoo_label_map.pbtxt')\n","generate_tf_record('workspace/data/eval.json', 'workspace/data/eval.record', 'workspace/data/shampoo_label_map.pbtxt')"]},{"cell_type":"markdown","metadata":{},"source":["## **Select and download a pretrained object detection model**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"akC8WVu5-1dC"},"outputs":[],"source":["# Select a pretrained object detection model\n","\n","MODELS = {\n","    \"SSD MobileNet v2 320x320\":\"http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_320x320_coco17_tpu-8.tar.gz\",\n","    \"EfficientDet D0 512x512\": \"http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d0_coco17_tpu-32.tar.gz\",\n","    \"EfficientDet D2 768x768\": \"http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d2_coco17_tpu-32.tar.gz\"\n","}\n","\n","#@title Model Selection {display-mode: \"form\", run: \"auto\"}\n","selected_model = \"EfficientDet D0 512x512\" # @param ['EfficientDet D0 512x512','EfficientDet D2 768x768','SSD MobileNet v2 320x320']\n","file = MODELS[selected_model].split('/')[-1]"]},{"cell_type":"markdown","metadata":{},"source":["Visit <a target=\"_blank\" href=\"https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md\">TensorFlow 2 Detection Model Zoo</a> to explore other pretrained object detection models."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":927,"status":"ok","timestamp":1643296853425,"user":{"displayName":"Anh Maciag","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjur-jNtzXZt6W_z-Jr2vWN1IkrFdQjwISgJ4pqbg=s64","userId":"01164446871095954383"},"user_tz":-60},"id":"QO7ZJvGFFnfg","outputId":"272061df-c98f-4fed-bfe0-9ab0a5e30b5a"},"outputs":[],"source":["!wget {MODELS[selected_model]} --directory-prefix workspace/pretrained_models\n","!tar -xf workspace/pretrained_models/{file} -C workspace/pretrained_models"]},{"cell_type":"markdown","metadata":{},"source":["## **Tweak the model's training configuration**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1643300171081,"user":{"displayName":"Anh Maciag","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjur-jNtzXZt6W_z-Jr2vWN1IkrFdQjwISgJ4pqbg=s64","userId":"01164446871095954383"},"user_tz":-60},"id":"gTAnTu4sGqSy","outputId":"eeecad31-506e-41f2-834c-1db2941c678d"},"outputs":[],"source":["model_dir = file.replace('.tar.gz', '')\n","pipeline_config_path = f'workspace/pretrained_models/{model_dir}/pipeline.config'\n","pipeline_config = config_util.get_configs_from_pipeline_file(pipeline_config_path)\n","\n","args = {'num_classes': 3, \n","        'batch_size': 4, \n","        'fine_tune_checkpoint_type': 'detection',\n","        'fine_tune_checkpoint_path': f'workspace/pretrained_models/{model_dir}/checkpoint/ckpt-0',\n","        'label_map_path': 'workspace/data/shampoo_label_map.pbtxt',\n","        'eval_input_path': 'workspace/data/eval.record',\n","        'train_input_path': 'workspace/data/train.record'}\n","\n","pipeline_config = update_pipeline_config(pipeline_config, args)        \n","pipeline_config = config_util.create_pipeline_proto_from_configs(pipeline_config)\n","config_util.save_pipeline_config(pipeline_config, 'workspace/trained_models')"]},{"cell_type":"markdown","metadata":{},"source":["## **Train a pretrained model**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["resize_output_cell(600)\n","train_dir = f'workspace/trained_models/{model_dir}'\n","%reload_ext tensorboard\n","%tensorboard --logdir={train_dir}/checkpoints"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":731010,"status":"ok","timestamp":1643303708162,"user":{"displayName":"Anh Maciag","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjur-jNtzXZt6W_z-Jr2vWN1IkrFdQjwISgJ4pqbg=s64","userId":"01164446871095954383"},"user_tz":-60},"id":"JvjGQgZKDaC5","outputId":"2cc16b98-89e4-4d43-8345-f7275f66b935"},"outputs":[],"source":["!python models/research/object_detection/model_main_tf2.py --pipeline_config_path=workspace/trained_models/pipeline.config \\\n","  --model_dir={train_dir}/checkpoints --checkpoint_every_n=100 --num_train_steps=500 --alsologtostderr"]},{"cell_type":"markdown","metadata":{},"source":["## **Get and visualize predictions**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Export a trained inference graph from checkpoints\n","# This stores neural network operations and trained parameters in a graph\n","\n","!cp models/research/object_detection/exporter_main_v2.py .\n","!python exporter_main_v2.py --input_type image_tensor \\\n","  --pipeline_config_path workspace/trained_models/pipeline.config  \\\n","  --trained_checkpoint_dir {train_dir}/checkpoints \\\n","  --output_directory {train_dir}"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Read in the trained model\n","saved_model_path = os.path.join(train_dir, 'saved_model')\n","detect_fn = tf.saved_model.load(saved_model_path)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Predict and visualize results\n","\n","resize_output_cell(800)\n","\n","with tf.io.gfile.GFile('workspace/data/eval.json', 'r') as file:\n","  eval_data = json.load(file)\n","\n","category_index = label_map_util.create_category_index_from_labelmap('./workspace/data/shampoo_label_map.pbtxt', use_display_name=True)\n","\n","for data in eval_data:\n","    \n","    url = data['Labeled Data']\n","    image_np, detections = get_prediction(url)\n","    viz_utils.visualize_boxes_and_labels_on_image_array(\n","          image_np,\n","          detections['detection_boxes'],\n","          detections['detection_classes'],\n","          detections['detection_scores'],\n","          category_index,\n","          use_normalized_coordinates=True,\n","          max_boxes_to_draw=200,\n","          min_score_thresh=.30,\n","          agnostic_mode=False)\n","    \n","    shampoo = category_index[detections['detection_classes'][np.argmax(np.max(detections['detection_multiclass_scores'], axis=1))]]['name']\n","    plt.figure(figsize=(20,20))\n","    plt.title(shampoo)\n","    plt.imshow(image_np)\n","    # plt.cla()\n","    # print('Done')\n","plt.show()"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyMwQWucI98sbK8CdmEbQWC8","name":"Untitled0.ipynb","provenance":[]},"interpreter":{"hash":"c2b8150c82711bfb3cb674bfdebf3e5eb9e430d88b9bd2f07284e3fba7a9902f"},"kernelspec":{"display_name":"Python 3.7.12 64-bit ('cvenv': venv)","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":2}

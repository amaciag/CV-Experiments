{"nbformat":4,"nbformat_minor":2,"metadata":{"colab":{"name":"Untitled0.ipynb","provenance":[],"authorship_tag":"ABX9TyMwQWucI98sbK8CdmEbQWC8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# **Object Detection**"],"metadata":{}},{"cell_type":"markdown","source":["<a target=\"_blank\" href=\"https://github.com/amaciag/CV-Experiments/blob/main/Shampoo_Object_Detection.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\"/>View source on GitHub</a>"],"metadata":{}},{"cell_type":"markdown","source":["Object Detection is the supervised learning process of locating and identifying objects in an image or video. This tutorial shows how to use some Google tensorflow pretrained model to train on a shampoo image dataset. Transfer learning and data augmentation techniques are incorporated."],"metadata":{}},{"cell_type":"markdown","source":["## **Install and import appropriate modules and their dependencies**"],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["import tensorflow as tf\n","from google.colab import drive\n","from IPython.display import Javascript\n","\n","def resize_output_cell():\n","  display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 300})'''))\n","\n","get_ipython().events.register('pre_run_cell', resize_output_cell)\n","drive.mount('/content/drive')"],"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: destination path 'models' already exists and is not an empty directory.\n"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ks2qm8O3Enj2","executionInfo":{"status":"ok","timestamp":1643296840270,"user_tz":-60,"elapsed":314,"user":{"displayName":"Anh Maciag","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjur-jNtzXZt6W_z-Jr2vWN1IkrFdQjwISgJ4pqbg=s64","userId":"01164446871095954383"}},"outputId":"8a50082f-f8a6-47d0-f5f8-221c18cdf06e"}},{"cell_type":"code","execution_count":null,"source":["!git clone https://github.com/tensorflow/models"],"outputs":[],"metadata":{"id":"N89qp8TWJsdR"}},{"cell_type":"code","execution_count":null,"source":["%%writefile models/research/object_detection/packages/tf2/setup.py\n","\"\"\"Setup script for object_detection with TF2.0.\"\"\"\n","import os\n","from setuptools import find_packages\n","from setuptools import setup\n","\n","REQUIRED_PACKAGES = [\n","    # Required for apache-beam with PY3\n","    'avro-python3',\n","    'apache-beam',\n","    'pillow',\n","    'lxml',\n","    'matplotlib',\n","    'Cython',\n","    'contextlib2',\n","    'tf-slim',\n","    'six',\n","    'pycocotools',\n","    'lvis',\n","    'scipy',\n","    'pandas',\n","    'tf-models-official==2.7.0',\n","    'tensorflow_io',\n","    'keras'\n","]\n","\n","setup(\n","    name='object_detection',\n","    version='0.1',\n","    install_requires=REQUIRED_PACKAGES,\n","    include_package_data=True,\n","    packages=(\n","        [p for p in find_packages() if p.startswith('object_detection')] +\n","        find_packages(where=os.path.join('.', 'slim'))),\n","    package_dir={\n","        'datasets': os.path.join('slim', 'datasets'),\n","        'nets': os.path.join('slim', 'nets'),\n","        'preprocessing': os.path.join('slim', 'preprocessing'),\n","        'deployment': os.path.join('slim', 'deployment'),\n","        'scripts': os.path.join('slim', 'scripts'),\n","    },\n","    description='Tensorflow Object Detection Library',\n","    python_requires='>3.6',\n",")\n","\n"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["%%bash\n","\n","sudo apt install -y protobuf-compiler\n","cd models/research/\n","protoc object_detection/protos/*.proto --python_out=.\n","cp object_detection/packages/tf2/setup.py .\n","python -m pip install .\n","pip install opencv-python-headless==4.1.2.30"],"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists...\n","Building dependency tree...\n","Reading state information...\n","protobuf-compiler is already the newest version (3.0.0-9.1ubuntu1).\n","0 upgraded, 0 newly installed, 0 to remove and 37 not upgraded.\n","Processing /content/models/research\n","Requirement already satisfied: avro-python3 in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.10.2)\n","Requirement already satisfied: apache-beam in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.35.0)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (7.1.2)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (4.2.6)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (3.2.2)\n","Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.29.26)\n","Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.5.5)\n","Requirement already satisfied: tf-slim in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.1.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.15.0)\n","Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.0.4)\n","Requirement already satisfied: lvis in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.5.3)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.4.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.1.5)\n","Requirement already satisfied: tf-models-official>=2.5.1 in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.7.0)\n","Requirement already satisfied: tensorflow_io in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.23.1)\n","Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.7.0)\n","Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.5.12)\n","Requirement already satisfied: py-cpuinfo>=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (8.0.0)\n","Requirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.3)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (6.0)\n","Requirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.5.0)\n","Requirement already satisfied: sacrebleu in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.0.0)\n","Requirement already satisfied: tensorflow>=2.7.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.7.0)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.1.96)\n","Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n","Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.15.0)\n","Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.5.5.62)\n","Requirement already satisfied: seqeval in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.2.2)\n","Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.0.1)\n","Requirement already satisfied: tensorflow-text>=2.7.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.7.3)\n","Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.12.10)\n","Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.19.5)\n","Requirement already satisfied: tensorflow-model-optimization>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.7.0)\n","Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.4.8)\n","Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.1)\n","Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.17.4)\n","Requirement already satisfied: google-auth<3dev,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.35.0)\n","Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.0.4)\n","Requirement already satisfied: google-api-core<3dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.26.3)\n","Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2018.9)\n","Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.19.3)\n","Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (57.4.0)\n","Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.54.0)\n","Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (21.3)\n","Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.27.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.2.4)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.62.3)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2021.10.8)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2.8.2)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (5.0.2)\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.24.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.7)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.4.8)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.10)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.0.10)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.2)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (3.10.0.2)\n","Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (2.7.0)\n","Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.0.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.43.0)\n","Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (2.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.13.3)\n","Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (12.0.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (0.23.1)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n","Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (0.37.1)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n","Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (2.7.0)\n","Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.0)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.5.2)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.0.1)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (0.6.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.6)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.6)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.8.1)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.0)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (4.10.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (3.7.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (3.1.1)\n","Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object-detection==0.1) (0.1.6)\n","Requirement already satisfied: orjson<4.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.6.6)\n","Requirement already satisfied: hdfs<3.0.0,>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (2.6.0)\n","Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.3.0)\n","Requirement already satisfied: fastavro<2,>=0.21.4 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.4.9)\n","Requirement already satisfied: pyarrow<7.0.0,>=0.15.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.0.0)\n","Requirement already satisfied: pymongo<4.0.0,>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.12.3)\n","Requirement already satisfied: proto-plus<2,>=1.7.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.19.9)\n","Requirement already satisfied: dill<0.3.2,>=0.3.1.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (0.3.1.1)\n","Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.7)\n","Requirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (0.6.2)\n","Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (1.3.2)\n","Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (4.1.2.30)\n","Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (0.11.0)\n","Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.3)\n","Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (2019.12.20)\n","Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (0.8.9)\n","Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (0.4.4)\n","Requirement already satisfied: portalocker in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (2.3.2)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.0.2)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (3.0.0)\n","Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->tf-models-official>=2.5.1->object-detection==0.1) (2.7.1)\n","Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2.3)\n","Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (21.4.0)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.16.0)\n","Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.6.0)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (5.4.0)\n","Building wheels for collected packages: object-detection\n","  Building wheel for object-detection (setup.py): started\n","  Building wheel for object-detection (setup.py): finished with status 'done'\n","  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1684828 sha256=a201a22731ab98f4be5ed4537899ac99c41d2bd2a99cff6d53a05d24ab469354\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-kbxgobhu/wheels/fa/a4/d2/e9a5057e414fd46c8e543d2706cd836d64e1fcd9eccceb2329\n","Successfully built object-detection\n","Installing collected packages: object-detection\n","  Attempting uninstall: object-detection\n","    Found existing installation: object-detection 0.1\n","    Uninstalling object-detection-0.1:\n","      Successfully uninstalled object-detection-0.1\n","Successfully installed object-detection-0.1\n"]},{"output_type":"stream","name":"stderr","text":["\n","WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n","\n","  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n","   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\n"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SPg1ILoWE63M","executionInfo":{"status":"ok","timestamp":1643296852510,"user_tz":-60,"elapsed":10920,"user":{"displayName":"Anh Maciag","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjur-jNtzXZt6W_z-Jr2vWN1IkrFdQjwISgJ4pqbg=s64","userId":"01164446871095954383"}},"outputId":"bf0a24c2-7683-4b98-89d2-752175bb5162"}},{"cell_type":"code","execution_count":null,"source":["%%writefile generate_tf_record.py\n","from __future__ import division\n","from __future__ import print_function\n","from __future__ import absolute_import\n","\n","import argparse\n","import os\n","import io\n","import json\n","import pandas as pd\n","import requests\n","import tensorflow as tf\n","import sys\n","# sys.path.append(\"./models/research\")\n","\n","from PIL import Image\n","from object_detection.utils import dataset_util, label_map_util\n","\n","def create_tf_example(data):\n","    \n","    # print(data['Labeled Data'])\n","    response = requests.get(data['Labeled Data'])\n","    encoded_jpg = response.content\n","    encoded_jpg_io = io.BytesIO(encoded_jpg)\n","    image = Image.open(encoded_jpg_io)\n","    width, height = image.size\n","\n","    xmins = []\n","    xmaxs = []\n","    ymins = []\n","    ymaxs = []\n","    classes_text = []\n","    classes = []\n","\n","    for obj in data['Label']['objects']:\n","        bbox = obj['bbox']\n","        xmin = bbox['left']\n","        ymin = bbox['top']\n","        xmax = xmin + bbox['width']\n","        ymax = ymin + bbox['height']\n","        xmins.append(xmin / width)\n","        xmaxs.append(xmax / width)\n","        ymins.append(ymin / height)\n","        ymaxs.append(ymax / height)\n","        classes_text.append(obj['title'].encode('utf8')) \n","        classes.append(label_map_dict[obj['title']])\n","    \n","    filename = data['External ID'].encode('utf8')\n","    image_format = b'jpg'\n","    tf_example = tf.train.Example(features=tf.train.Features(feature={\n","            'image/height': dataset_util.int64_feature(height),\n","            'image/width': dataset_util.int64_feature(width),\n","            'image/filename': dataset_util.bytes_feature(filename),\n","            'image/source_id': dataset_util.bytes_feature(filename),\n","            'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n","            'image/format': dataset_util.bytes_feature(image_format),\n","            'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n","            'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n","            'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n","            'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n","            'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n","            'image/object/class/label': dataset_util.int64_list_feature(classes),\n","        }))\n","    return tf_example\n","\n","def main(args):\n","    \n","    with tf.io.gfile.GFile(args.json_input, 'r') as file:\n","        dataset = json.load(file)\n","    \n","    writer = tf.io.TFRecordWriter(args.output_path)\n","    for data in dataset:\n","        tf_example = create_tf_example(data)\n","        writer.write(tf_example.SerializeToString())\n","    writer.close()\n","    print(f'Successfully created TF-records {args.output_path}')\n","\n","\n","if __name__ == '__main__':\n","    argparser = argparse.ArgumentParser()\n","    argparser.add_argument('--json-input')\n","    argparser.add_argument('--output-path')\n","    argparser.add_argument('--label-map')\n","    args = argparser.parse_args()\n","    \n","    label_map_dict = label_map_util.get_label_map_dict(args.label_map)\n","    main(args)"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["%%bash\n","\n","if [ ! -d workspace ]; then\n","  mkdir -p workspace/{pretrained_models,trained_models,data}\n","fi\n","\n","wget -O workspace/data/eval.json https://raw.githubusercontent.com/amaciag/CV-Experiments/main/data/eval.json\n","wget -O workspace/data/train.json https://raw.githubusercontent.com/amaciag/CV-Experiments/main/data/train.json"],"outputs":[],"metadata":{"id":"w-QHrCGdCygK"}},{"cell_type":"code","execution_count":null,"source":["items = [{\n","  'id': '1',\n","  'name': '\"Loreal\"'\n","},\n","{\n","  'id': '2',\n","  'name': '\"Pantene\"'\n","},\n","{\n","  'id': '3',\n","  'name': '\"Head_&_Shoulders\"'\n","}]\n","\n","expression = ''\n","for item in items:\n","  expression += 'item {\\n'\n","  for key,value in item.items():\n","    expression += 2*' ' + key + ': ' + value + '\\n'\n","  expression += '}\\n'\n","\n","with open('workspace/data/shampoo_label_map.pbtxt', 'w') as f:\n","  f.write(expression)\n","print(expression)"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["!python generate_tf_record.py --json-input workspace/data/train.json --output-path workspace/data/train.record --label-map workspace/data/shampoo_label_map.pbtxt\n","!python generate_tf_record.py --json-input workspace/data/eval.json --output-path workspace/data/eval.record --label-map workspace/data/shampoo_label_map.pbtxt"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["MODELS = {\n","    \"EfficientDet D0 512x512\": \"http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d0_coco17_tpu-32.tar.gz\",\n","    \"EfficientDet D2 768x768\": \"http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d2_coco17_tpu-32.tar.gz\"\n","}\n","\n","selected_model = \"EfficientDet D0 512x512\"\n","file = MODELS[selected_model].split('/')[-1]"],"outputs":[],"metadata":{"id":"akC8WVu5-1dC"}},{"cell_type":"code","execution_count":null,"source":["!wget {MODELS[selected_model]} --directory-prefix workspace/pretrained_models\n","!tar -xf workspace/pretrained_models/{file} -C workspace/pretrained_models"],"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-01-27 15:20:52--  http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d0_coco17_tpu-32.tar.gz\n","Resolving download.tensorflow.org (download.tensorflow.org)... 142.251.5.128, 2a00:1450:400c:c1b::80\n","Connecting to download.tensorflow.org (download.tensorflow.org)|142.251.5.128|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 30736482 (29M) [application/x-tar]\n","Saving to: ‘workspace/pretrained_models/efficientdet_d0_coco17_tpu-32.tar.gz.1’\n","\n","efficientdet_d0_coc 100%[===================>]  29.31M   168MB/s    in 0.2s    \n","\n","2022-01-27 15:20:52 (168 MB/s) - ‘workspace/pretrained_models/efficientdet_d0_coco17_tpu-32.tar.gz.1’ saved [30736482/30736482]\n","\n"]}],"metadata":{"id":"QO7ZJvGFFnfg","executionInfo":{"status":"ok","timestamp":1643296853425,"user_tz":-60,"elapsed":927,"user":{"displayName":"Anh Maciag","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjur-jNtzXZt6W_z-Jr2vWN1IkrFdQjwISgJ4pqbg=s64","userId":"01164446871095954383"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"272061df-c98f-4fed-bfe0-9ab0a5e30b5a"}},{"cell_type":"code","execution_count":null,"source":["from object_detection.utils import config_util\n","\n","model_dir = file.replace('.tar.gz', '')\n","pipeline_config = config_util.get_configs_from_pipeline_file(f'workspace/pretrained_models/{model_dir}/pipeline.config')\n","\n","pipeline_config['model'].ssd.num_classes=3\n","pipeline_config['train_config'].batch_size=4\n","pipeline_config['train_config'].fine_tune_checkpoint_type='detection'\n","pipeline_config['train_config'].fine_tune_checkpoint=f'workspace/pretrained_models/{model_dir}/checkpoint/ckpt-0'\n","pipeline_config['eval_input_config'].label_map_path='workspace/data/shampoo_label_map.pbtxt'\n","pipeline_config['eval_input_config'].tf_record_input_reader.input_path[0]='workspace/data/eval.record'\n","pipeline_config['train_input_config'].label_map_path='workspace/data/shampoo_label_map.pbtxt'\n","pipeline_config['train_input_config'].tf_record_input_reader.input_path[0]='workspace/data/train.record'\n","\n","pipeline_config = config_util.create_pipeline_proto_from_configs(pipeline_config)\n","config_util.save_pipeline_config(pipeline_config, 'workspace/trained_models')"],"outputs":[{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Writing pipeline config file to workspace/trained_models/pipeline.config\n"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gTAnTu4sGqSy","executionInfo":{"status":"ok","timestamp":1643300171081,"user_tz":-60,"elapsed":4,"user":{"displayName":"Anh Maciag","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjur-jNtzXZt6W_z-Jr2vWN1IkrFdQjwISgJ4pqbg=s64","userId":"01164446871095954383"}},"outputId":"eeecad31-506e-41f2-834c-1db2941c678d"}},{"cell_type":"code","execution_count":null,"source":["%reload_ext tensorboard\n","%tensorboard --logdir=drive/MyDrive/CV-Experiments-main/efficientdet_d0/v2"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["!python models/research/object_detection/model_main_tf2.py --pipeline_config_path=workspace/trained_models/pipeline.config \\\n","  --model_dir=drive/MyDrive/CV-Experiments-main/efficientdet_d0/v3 --checkpoint_every_n=10 --num_train_steps=100 --alsologtostderr"],"outputs":[{"output_type":"stream","name":"stdout","text":["2022-01-27 17:03:02.271334: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n","I0127 17:03:02.275178 140258431371136 mirrored_strategy.py:376] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n","INFO:tensorflow:Maybe overwriting train_steps: 2000\n","I0127 17:03:02.280510 140258431371136 config_util.py:552] Maybe overwriting train_steps: 2000\n","INFO:tensorflow:Maybe overwriting use_bfloat16: False\n","I0127 17:03:02.280679 140258431371136 config_util.py:552] Maybe overwriting use_bfloat16: False\n","I0127 17:03:02.292429 140258431371136 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b0\n","I0127 17:03:02.292589 140258431371136 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 64\n","I0127 17:03:02.292690 140258431371136 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 3\n","I0127 17:03:02.297890 140258431371136 efficientnet_model.py:147] round_filter input=32 output=32\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0127 17:03:02.323643 140258431371136 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0127 17:03:02.325933 140258431371136 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0127 17:03:02.328582 140258431371136 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0127 17:03:02.329709 140258431371136 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0127 17:03:02.338353 140258431371136 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0127 17:03:02.342704 140258431371136 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0127 17:03:02.349564 140258431371136 efficientnet_model.py:147] round_filter input=32 output=32\n","I0127 17:03:02.349700 140258431371136 efficientnet_model.py:147] round_filter input=16 output=16\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0127 17:03:02.366453 140258431371136 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0127 17:03:02.367688 140258431371136 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0127 17:03:02.369760 140258431371136 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0127 17:03:02.370827 140258431371136 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0127 17:03:02.471175 140258431371136 efficientnet_model.py:147] round_filter input=16 output=16\n","I0127 17:03:02.471442 140258431371136 efficientnet_model.py:147] round_filter input=24 output=24\n","I0127 17:03:02.798044 140258431371136 efficientnet_model.py:147] round_filter input=24 output=24\n","I0127 17:03:02.798245 140258431371136 efficientnet_model.py:147] round_filter input=40 output=40\n","I0127 17:03:03.134630 140258431371136 efficientnet_model.py:147] round_filter input=40 output=40\n","I0127 17:03:03.134865 140258431371136 efficientnet_model.py:147] round_filter input=80 output=80\n","I0127 17:03:03.625721 140258431371136 efficientnet_model.py:147] round_filter input=80 output=80\n","I0127 17:03:03.625939 140258431371136 efficientnet_model.py:147] round_filter input=112 output=112\n","I0127 17:03:04.125999 140258431371136 efficientnet_model.py:147] round_filter input=112 output=112\n","I0127 17:03:04.126214 140258431371136 efficientnet_model.py:147] round_filter input=192 output=192\n","I0127 17:03:04.783447 140258431371136 efficientnet_model.py:147] round_filter input=192 output=192\n","I0127 17:03:04.783667 140258431371136 efficientnet_model.py:147] round_filter input=320 output=320\n","I0127 17:03:04.953655 140258431371136 efficientnet_model.py:147] round_filter input=1280 output=1280\n","I0127 17:03:05.016680 140258431371136 efficientnet_model.py:457] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:564: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","rename to distribute_datasets_from_function\n","W0127 17:03:05.075722 140258431371136 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:564: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","rename to distribute_datasets_from_function\n","INFO:tensorflow:Reading unweighted datasets: ['workspace/data/train.record']\n","I0127 17:03:05.081002 140258431371136 dataset_builder.py:163] Reading unweighted datasets: ['workspace/data/train.record']\n","INFO:tensorflow:Reading record datasets for input file: ['workspace/data/train.record']\n","I0127 17:03:05.081265 140258431371136 dataset_builder.py:80] Reading record datasets for input file: ['workspace/data/train.record']\n","INFO:tensorflow:Number of filenames to read: 1\n","I0127 17:03:05.081439 140258431371136 dataset_builder.py:81] Number of filenames to read: 1\n","WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n","W0127 17:03:05.081576 140258431371136 dataset_builder.py:88] num_readers has been reduced to 1 to match input file shards.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n","W0127 17:03:05.084548 140258431371136 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","W0127 17:03:05.110851 140258431371136 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n","W0127 17:03:14.868090 140258431371136 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:465: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","W0127 17:03:20.111732 140258431371136 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:465: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","2022-01-27 17:03:24.362168: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at multi_device_iterator_ops.cc:789 : NOT_FOUND: Resource AnonymousMultiDeviceIterator/AnonymousMultiDeviceIterator0/N10tensorflow4data12_GLOBAL__N_119MultiDeviceIteratorE does not exist.\n","/usr/local/lib/python3.7/dist-packages/keras/backend.py:414: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n","  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:620: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use fn_output_signature instead\n","W0127 17:04:02.956227 140253606876928 deprecation.py:551] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:620: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use fn_output_signature instead\n","WARNING:tensorflow:Gradients do not exist for variables ['top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n","W0127 17:04:13.318845 140253606876928 utils.py:80] Gradients do not exist for variables ['top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n","W0127 17:04:27.336978 140253606876928 utils.py:80] Gradients do not exist for variables ['top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n","W0127 17:04:40.745397 140253606876928 utils.py:80] Gradients do not exist for variables ['top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n","W0127 17:04:54.375685 140253606876928 utils.py:80] Gradients do not exist for variables ['top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n","INFO:tensorflow:Step 1100 per-step time 1.321s\n","I0127 17:06:14.581379 140258431371136 model_lib_v2.py:707] Step 1100 per-step time 1.321s\n","INFO:tensorflow:{'Loss/classification_loss': 0.589794,\n"," 'Loss/localization_loss': 0.00548777,\n"," 'Loss/regularization_loss': 0.030297432,\n"," 'Loss/total_loss': 0.6255792,\n"," 'learning_rate': 0.03576}\n","I0127 17:06:14.581805 140258431371136 model_lib_v2.py:708] {'Loss/classification_loss': 0.589794,\n"," 'Loss/localization_loss': 0.00548777,\n"," 'Loss/regularization_loss': 0.030297432,\n"," 'Loss/total_loss': 0.6255792,\n"," 'learning_rate': 0.03576}\n","INFO:tensorflow:Step 1200 per-step time 0.593s\n","I0127 17:07:13.851436 140258431371136 model_lib_v2.py:707] Step 1200 per-step time 0.593s\n","INFO:tensorflow:{'Loss/classification_loss': 0.320204,\n"," 'Loss/localization_loss': 0.0055540595,\n"," 'Loss/regularization_loss': 0.030660912,\n"," 'Loss/total_loss': 0.35641897,\n"," 'learning_rate': 0.03892}\n","I0127 17:07:13.851860 140258431371136 model_lib_v2.py:708] {'Loss/classification_loss': 0.320204,\n"," 'Loss/localization_loss': 0.0055540595,\n"," 'Loss/regularization_loss': 0.030660912,\n"," 'Loss/total_loss': 0.35641897,\n"," 'learning_rate': 0.03892}\n","INFO:tensorflow:Step 1300 per-step time 0.588s\n","I0127 17:08:12.660087 140258431371136 model_lib_v2.py:707] Step 1300 per-step time 0.588s\n","INFO:tensorflow:{'Loss/classification_loss': 0.42191887,\n"," 'Loss/localization_loss': 0.006290237,\n"," 'Loss/regularization_loss': 0.031022936,\n"," 'Loss/total_loss': 0.45923203,\n"," 'learning_rate': 0.04208}\n","I0127 17:08:12.660512 140258431371136 model_lib_v2.py:708] {'Loss/classification_loss': 0.42191887,\n"," 'Loss/localization_loss': 0.006290237,\n"," 'Loss/regularization_loss': 0.031022936,\n"," 'Loss/total_loss': 0.45923203,\n"," 'learning_rate': 0.04208}\n","INFO:tensorflow:Step 1400 per-step time 0.587s\n","I0127 17:09:11.326573 140258431371136 model_lib_v2.py:707] Step 1400 per-step time 0.587s\n","INFO:tensorflow:{'Loss/classification_loss': 0.3059987,\n"," 'Loss/localization_loss': 0.0037148658,\n"," 'Loss/regularization_loss': 0.031331055,\n"," 'Loss/total_loss': 0.34104463,\n"," 'learning_rate': 0.04524}\n","I0127 17:09:11.326960 140258431371136 model_lib_v2.py:708] {'Loss/classification_loss': 0.3059987,\n"," 'Loss/localization_loss': 0.0037148658,\n"," 'Loss/regularization_loss': 0.031331055,\n"," 'Loss/total_loss': 0.34104463,\n"," 'learning_rate': 0.04524}\n","INFO:tensorflow:Step 1500 per-step time 0.589s\n","I0127 17:10:10.184070 140258431371136 model_lib_v2.py:707] Step 1500 per-step time 0.589s\n","INFO:tensorflow:{'Loss/classification_loss': 0.37640953,\n"," 'Loss/localization_loss': 0.0055501214,\n"," 'Loss/regularization_loss': 0.03165263,\n"," 'Loss/total_loss': 0.41361228,\n"," 'learning_rate': 0.0484}\n","I0127 17:10:10.184504 140258431371136 model_lib_v2.py:708] {'Loss/classification_loss': 0.37640953,\n"," 'Loss/localization_loss': 0.0055501214,\n"," 'Loss/regularization_loss': 0.03165263,\n"," 'Loss/total_loss': 0.41361228,\n"," 'learning_rate': 0.0484}\n","INFO:tensorflow:Step 1600 per-step time 0.589s\n","I0127 17:11:09.046834 140258431371136 model_lib_v2.py:707] Step 1600 per-step time 0.589s\n","INFO:tensorflow:{'Loss/classification_loss': 0.326162,\n"," 'Loss/localization_loss': 0.0038057314,\n"," 'Loss/regularization_loss': 0.031969268,\n"," 'Loss/total_loss': 0.36193702,\n"," 'learning_rate': 0.05156}\n","I0127 17:11:09.047266 140258431371136 model_lib_v2.py:708] {'Loss/classification_loss': 0.326162,\n"," 'Loss/localization_loss': 0.0038057314,\n"," 'Loss/regularization_loss': 0.031969268,\n"," 'Loss/total_loss': 0.36193702,\n"," 'learning_rate': 0.05156}\n","INFO:tensorflow:Step 1700 per-step time 0.588s\n","I0127 17:12:07.798498 140258431371136 model_lib_v2.py:707] Step 1700 per-step time 0.588s\n","INFO:tensorflow:{'Loss/classification_loss': 0.5408907,\n"," 'Loss/localization_loss': 0.0042935987,\n"," 'Loss/regularization_loss': 0.032319818,\n"," 'Loss/total_loss': 0.57750416,\n"," 'learning_rate': 0.05472}\n","I0127 17:12:07.798932 140258431371136 model_lib_v2.py:708] {'Loss/classification_loss': 0.5408907,\n"," 'Loss/localization_loss': 0.0042935987,\n"," 'Loss/regularization_loss': 0.032319818,\n"," 'Loss/total_loss': 0.57750416,\n"," 'learning_rate': 0.05472}\n","INFO:tensorflow:Step 1800 per-step time 0.587s\n","I0127 17:13:06.542230 140258431371136 model_lib_v2.py:707] Step 1800 per-step time 0.587s\n","INFO:tensorflow:{'Loss/classification_loss': 0.20547006,\n"," 'Loss/localization_loss': 0.0026132795,\n"," 'Loss/regularization_loss': 0.032694444,\n"," 'Loss/total_loss': 0.24077778,\n"," 'learning_rate': 0.05788}\n","I0127 17:13:06.542696 140258431371136 model_lib_v2.py:708] {'Loss/classification_loss': 0.20547006,\n"," 'Loss/localization_loss': 0.0026132795,\n"," 'Loss/regularization_loss': 0.032694444,\n"," 'Loss/total_loss': 0.24077778,\n"," 'learning_rate': 0.05788}\n","INFO:tensorflow:Step 1900 per-step time 0.587s\n","I0127 17:14:05.270049 140258431371136 model_lib_v2.py:707] Step 1900 per-step time 0.587s\n","INFO:tensorflow:{'Loss/classification_loss': 0.33281907,\n"," 'Loss/localization_loss': 0.008744359,\n"," 'Loss/regularization_loss': 0.03314092,\n"," 'Loss/total_loss': 0.37470436,\n"," 'learning_rate': 0.06104}\n","I0127 17:14:05.270524 140258431371136 model_lib_v2.py:708] {'Loss/classification_loss': 0.33281907,\n"," 'Loss/localization_loss': 0.008744359,\n"," 'Loss/regularization_loss': 0.03314092,\n"," 'Loss/total_loss': 0.37470436,\n"," 'learning_rate': 0.06104}\n","INFO:tensorflow:Step 2000 per-step time 0.585s\n","I0127 17:15:03.734243 140258431371136 model_lib_v2.py:707] Step 2000 per-step time 0.585s\n","INFO:tensorflow:{'Loss/classification_loss': 0.22026847,\n"," 'Loss/localization_loss': 0.002203581,\n"," 'Loss/regularization_loss': 0.033554,\n"," 'Loss/total_loss': 0.25602606,\n"," 'learning_rate': 0.06420001}\n","I0127 17:15:03.734762 140258431371136 model_lib_v2.py:708] {'Loss/classification_loss': 0.22026847,\n"," 'Loss/localization_loss': 0.002203581,\n"," 'Loss/regularization_loss': 0.033554,\n"," 'Loss/total_loss': 0.25602606,\n"," 'learning_rate': 0.06420001}\n"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JvjGQgZKDaC5","executionInfo":{"status":"ok","timestamp":1643303708162,"user_tz":-60,"elapsed":731010,"user":{"displayName":"Anh Maciag","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjur-jNtzXZt6W_z-Jr2vWN1IkrFdQjwISgJ4pqbg=s64","userId":"01164446871095954383"}},"outputId":"2cc16b98-89e4-4d43-8345-f7275f66b935"}},{"cell_type":"code","execution_count":null,"source":["# LOG_DIR = 'workspace/efficientdet_d0/v1'\n","# get_ipython().system_raw(\n","#     'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n","#     .format(LOG_DIR)\n","# )"],"outputs":[],"metadata":{"id":"NO051KtxWEvo"}},{"cell_type":"code","execution_count":null,"source":["# get_ipython().system_raw('./ngrok http 6006 &')"],"outputs":[],"metadata":{"id":"-Zsd9Z9YdFwR"}},{"cell_type":"code","execution_count":null,"source":["# !curl -s http://localhost:4040/api/tunnels | python -c \\\n","#   \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""],"outputs":[{"output_type":"stream","name":"stdout","text":["http://44b8-35-205-166-217.ngrok.io\n"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vBgIIXRGWNRd","executionInfo":{"status":"ok","timestamp":1643302520114,"user_tz":-60,"elapsed":455,"user":{"displayName":"Anh Maciag","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjur-jNtzXZt6W_z-Jr2vWN1IkrFdQjwISgJ4pqbg=s64","userId":"01164446871095954383"}},"outputId":"fdb2d25b-2ff0-4a03-de3a-1cfed84d4ad2"}},{"cell_type":"code","execution_count":null,"source":["%%bash\n","cp models/research/object_detection/exporter_main_v2.py .\n","python exporter_main_v2.py --input_type image_tensor \\\n","  --pipeline_config_path workspace/trained_models/pipeline.config  \\\n","  --trained_checkpoint_dir drive/MyDrive/CV-Experiments-main/efficientdet_d0/v2 \\\n","  --output_directory sample_model"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["import time\n","import tensorflow as tf\n","from object_detection.utils import label_map_util\n","from object_detection.utils import visualization_utils as viz_utils\n","\n","PATH_TO_SAVED_MODEL = './sample_model/saved_model'\n","\n","detect_fn = tf.saved_model.load(PATH_TO_SAVED_MODEL)"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["import json\n","import requests\n","import io\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","%matplotlib inline\n","# import matplotlib.pyplot as plt\n","# plt.rcParams.update({'figure.max_open_warning': 0})\n","\n","def load_image_into_numpy_array(path):\n","    return np.array(Image.open(path))\n","\n","with tf.io.gfile.GFile('workspace/data/eval.json', 'r') as file:\n","        eval_data = json.load(file)\n","\n","category_index = label_map_util.create_category_index_from_labelmap('./workspace/data/shampoo_label_map.pbtxt', use_display_name=True)\n","\n","for data in eval_data:\n","    \n","    url = data['Labeled Data']\n","    response = requests.get(url)\n","    encoded = io.BytesIO(response.content)\n","    image_np = load_image_into_numpy_array(encoded)\n","    input_tensor = tf.convert_to_tensor(image_np)\n","    input_tensor = input_tensor[tf.newaxis, ...]\n","    detections = detect_fn(input_tensor)\n","    \n","\n","    # All outputs are batches tensors.\n","    # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n","    # We're only interested in the first num_detections.\n","    num_detections = int(detections.pop('num_detections'))\n","    detections = {key: value[0, :num_detections].numpy()\n","                   for key, value in detections.items()}\n","    detections['num_detections'] = num_detections\n","\n","    # detection_classes should be ints.\n","    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n","\n","    image_np_with_detections = image_np.copy()\n","\n","    viz_utils.visualize_boxes_and_labels_on_image_array(\n","          image_np_with_detections,\n","          detections['detection_boxes'],\n","          detections['detection_classes'],\n","          detections['detection_scores'],\n","          category_index,\n","          use_normalized_coordinates=True,\n","          max_boxes_to_draw=200,\n","          min_score_thresh=.30,\n","          agnostic_mode=False)\n","    \n","    shampoo = category_index[detections['detection_classes'][np.argmax(np.max(detections['detection_multiclass_scores'], axis=1))]]['name']\n","    plt.figure(figsize=(20,20))\n","    plt.title(shampoo)\n","    plt.imshow(image_np_with_detections)\n","    # plt.cla()\n","    # print('Done')\n","plt.show()"],"outputs":[],"metadata":{}}]}